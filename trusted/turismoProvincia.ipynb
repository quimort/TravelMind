{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd12423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import upper, col\n",
    "import os\n",
    "import utils\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession,DataFrame\n",
    "import requests\n",
    "import json \n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce20ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------+----------------+--------------------+--------------------+--------+--------------+--------------+\n",
      "| AÑO|MES|CCAA_ORIGEN|PROVINCIA_ORIGEN|        CCAA_DESTINO|   PROVINCIA_DESTINO|TURISTAS|PERNOCTACIONES|ESTANCIA_MEDIA|\n",
      "+----+---+-----------+----------------+--------------------+--------------------+--------+--------------+--------------+\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|               Cádiz|  8910.0|       33536.0|           3.8|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|             Córdoba|  3468.0|       11981.0|           3.5|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|             Granada| 49626.0|      141865.0|           2.9|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|              Huelva|  2801.0|       10920.0|           3.9|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|                Jaén|  9247.0|       34155.0|           3.7|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|              Málaga| 20363.0|       63758.0|           3.1|\n",
      "|2019|  7|  Andalucía|         Almería|           Andalucía|             Sevilla|  6920.0|       21577.0|           3.1|\n",
      "|2019|  7|  Andalucía|         Almería|              Aragón|              Huesca|   666.0|        4719.0|           7.1|\n",
      "|2019|  7|  Andalucía|         Almería|              Aragón|              Teruel|   515.0|        2338.0|           4.5|\n",
      "|2019|  7|  Andalucía|         Almería|              Aragón|            Zaragoza|   975.0|        4919.0|           5.0|\n",
      "|2019|  7|  Andalucía|         Almería|            Canarias|          Las Palmas|   682.0|        5210.0|           7.6|\n",
      "|2019|  7|  Andalucía|         Almería|            Canarias|Santa Cruz de Ten...|  1027.0|        6791.0|           6.6|\n",
      "|2019|  7|  Andalucía|         Almería|           Cantabria|           Cantabria|   895.0|        5924.0|           6.6|\n",
      "|2019|  7|  Andalucía|         Almería|Castilla - La Mancha|            Albacete|  1655.0|        6192.0|           3.7|\n",
      "|2019|  7|  Andalucía|         Almería|Castilla - La Mancha|         Ciudad Real|  2183.0|        8677.0|           4.0|\n",
      "|2019|  7|  Andalucía|         Almería|Castilla - La Mancha|              Cuenca|   535.0|        2207.0|           4.1|\n",
      "|2019|  7|  Andalucía|         Almería|Castilla - La Mancha|         Guadalajara|   658.0|        3131.0|           4.8|\n",
      "|2019|  7|  Andalucía|         Almería|Castilla - La Mancha|              Toledo|  1332.0|        5313.0|           4.0|\n",
      "|2019|  7|  Andalucía|         Almería|     Castilla y León|              Burgos|   650.0|        3303.0|           5.1|\n",
      "|2019|  7|  Andalucía|         Almería|     Castilla y León|                León|   396.0|        2586.0|           6.5|\n",
      "+----+---+-----------+----------------+--------------------+--------------------+--------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = utils.create_context()\n",
    "db_name = \"landing\"\n",
    "table_name = \"turismo_Provincia\"\n",
    "\n",
    "\n",
    "\n",
    "df = utils.read_iceberg_table(spark,db_name,table_name)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b13b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Reading landing Parquet from c:\\Users\\joaqu\\OneDrive\\Documents\\AAmaster_UPC\\TFM\\TravelMind\\POC\\landing\\data\\landing\\turismo_Provincia\n",
      "→ Writing trusted CSV to c:\\Users\\joaqu\\OneDrive\\Documents\\AAmaster_UPC\\TFM\\TravelMind\\POC\\trusted\\data\\trusted\\turismo_Provincia_clean_csv\n",
      "✅ Trusted zone load complete (CSV).\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import upper, col\n",
    "\n",
    "# Pin Python for Spark workers & driver\n",
    "os.environ[\"PYSPARK_PYTHON\"]        = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "def main():\n",
    "    # 1) Determine base POC folder (one level up from CWD)\n",
    "    cwd = os.getcwd()  \n",
    "    poc_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "\n",
    "    # 2) Landing parquet actually lives under POC/landing/data/landing/turismo_Provincia\n",
    "    landing_dir = os.path.join(poc_root, \"landing\", \"data\", \"landing\", \"turismo_Provincia\")\n",
    "    print(\"→ Reading landing Parquet from\", landing_dir)\n",
    "\n",
    "    # 3) Start Spark session\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "          .appName(\"TrustedCSVLoad\")\n",
    "          .config(\"spark.master\", \"local[*]\")\n",
    "          .config(\"spark.driver.memory\", \"2g\")\n",
    "          .getOrCreate()\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 4) Read landing Parquet\n",
    "        if not os.path.isdir(landing_dir):\n",
    "            raise FileNotFoundError(f\"Landing dir not found: {landing_dir}\")\n",
    "        df = spark.read.parquet(landing_dir)\n",
    "\n",
    "        # 5) Clean & normalize\n",
    "        df_clean = df.dropna()\n",
    "        for c in [\"CCAA_ORIGEN\",\"PROVINCIA_ORIGEN\",\"CCAA_DESTINO\",\"PROVINCIA_DESTINO\"]:\n",
    "            df_clean = df_clean.withColumn(c, upper(col(c)))\n",
    "\n",
    "        # 6) Write trusted CSV under POC/trusted/data/trusted/…\n",
    "        tgt_dir = os.path.join(poc_root, \"trusted\", \"data\", \"trusted\", \"turismo_Provincia_clean_csv\")\n",
    "        os.makedirs(tgt_dir, exist_ok=True)\n",
    "        print(\"→ Writing trusted CSV to\", tgt_dir)\n",
    "\n",
    "        (\n",
    "            df_clean\n",
    "              .repartition(1)\n",
    "              .write\n",
    "              .mode(\"overwrite\")\n",
    "              .option(\"header\", True)\n",
    "              .csv(tgt_dir)\n",
    "        )\n",
    "\n",
    "        print(\"✅ Trusted zone load complete (CSV).\")\n",
    "\n",
    "    finally:\n",
    "        spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350ffa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Reading spark_catalog.landing.turismo_Provincia\n",
      "→ Writing spark_catalog.exploitation.turismo_Provincia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupción de una conexión existente por el host remoto\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o64.createOrReplace",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m tgt_db, tgt_tbl = \u001b[33m\"\u001b[39m\u001b[33mexploitation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mturismo_Provincia\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m→ Writing spark_catalog.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtgt_db\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtgt_tbl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43moverwrite_iceberg_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_tbl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Exploitation load complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m spark.stop()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaqu\\OneDrive\\Documents\\AAmaster_UPC\\TFM\\TravelMind\\trusted\\utils.py:34\u001b[39m, in \u001b[36moverwrite_iceberg_table\u001b[39m\u001b[34m(spark, df, db_name, table_name)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moverwrite_iceberg_table\u001b[39m(spark, df, db_name, table_name):\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Fully qualify the catalog\u001b[39;00m\n\u001b[32m     31\u001b[39m     spark.sql(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCREATE NAMESPACE IF NOT EXISTS spark_catalog.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriteTo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspark_catalog.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdb_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m      \u001b[49m\u001b[43m.\u001b[49m\u001b[43musing\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miceberg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43m      \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreateOrReplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:2100\u001b[39m, in \u001b[36mDataFrameWriterV2.createOrReplace\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2090\u001b[39m \u001b[38;5;129m@since\u001b[39m(\u001b[32m3.1\u001b[39m)\n\u001b[32m   2091\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreateOrReplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2092\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2093\u001b[39m \u001b[33;03m    Create a new table or replace an existing table with the contents of the data frame.\u001b[39;00m\n\u001b[32m   2094\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2098\u001b[39m \u001b[33;03m    If the table exists, its configuration and data will be replaced.\u001b[39;00m\n\u001b[32m   2099\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2100\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreateOrReplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaqu\\.virtualenvs\\TravelMind--WcSvJCM\\Lib\\site-packages\\py4j\\protocol.py:334\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    335\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    336\u001b[39m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name))\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28mtype\u001b[39m = answer[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mPy4JError\u001b[39m: An error occurred while calling o64.createOrReplace"
     ]
    }
   ],
   "source": [
    "# 1) Re-use the same Iceberg-aware session for read & write\n",
    "spark = utils.create_context()\n",
    "\n",
    "\n",
    "# Read landing-zone Iceberg table\n",
    "src_db, src_tbl = \"landing\", \"turismo_Provincia\"\n",
    "print(f\"→ Reading spark_catalog.{src_db}.{src_tbl}\")\n",
    "df = utils.read_iceberg_table(spark, src_db, src_tbl)\n",
    "# 5) Clean & normalize\n",
    "df_clean = df.dropna()\n",
    "for c in [\"CCAA_ORIGEN\",\"PROVINCIA_ORIGEN\",\"CCAA_DESTINO\",\"PROVINCIA_DESTINO\"]:\n",
    "    df_clean = df_clean.withColumn(c, upper(col(c)))\n",
    "# Write into exploitation zone\n",
    "tgt_db, tgt_tbl = \"exploitation\", \"turismo_Provincia\"\n",
    "print(f\"→ Writing spark_catalog.{tgt_db}.{tgt_tbl}\")\n",
    "utils.overwrite_iceberg_table(spark, df_clean, tgt_db, tgt_tbl)\n",
    "\n",
    "print(\"✅ Exploitation load complete.\")\n",
    "\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TravelMind--WcSvJCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
