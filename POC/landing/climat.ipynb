{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c76b7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, LongType, DecimalType, FloatType, DoubleType, IntegerType, BooleanType, MapType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, coalesce, lit, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88cb813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear context spark\n",
    "spark = utils.create_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a26dd4",
   "metadata": {},
   "source": [
    "READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed228dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"local_db\"\n",
    "table_name = \"aemet\"\n",
    "df= utils.read_iceberg_table( spark, db_name, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a1d9c",
   "metadata": {},
   "source": [
    "FUNCION IMPUTAR VALORES NUMERICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83a1d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeNumericColumns(\n",
    "    df: DataFrame,\n",
    "    constant_value: float = 999.0,\n",
    "    columns_to_impute: list = None\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Imputa valores NULL en columnas numéricas (IntegerType, FloatType, LongType, DoubleType, DecimalType) \n",
    "    de un DataFrame de Spark con un valor constante especificado.\n",
    "\n",
    "    Esta función opera en columnas que *ya* son de tipo numérico.\n",
    "    Si sus valores \"vacíos\" se representan actualmente como cadenas vacías (\"\") \n",
    "    u otro texto no numérico en una columna StringType, primero debe convertirlos a \n",
    "    valores NULL y convertir la columna a un tipo numérico mediante un paso de preprocesamiento.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): El Spark DataFrame.\n",
    "        constant_value (float): El valor constante para imputación. Por defecto será 999.0.\n",
    "        columns_to_impute (list, optional): Una lista de nombres de columnas numéricas específicas para imputar.\n",
    "                                            Si no hay ninguno, se imputarán todas las columnas numéricas.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Un nuevo Spark DataFrame con NULL imputados en columnas numéricas.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(df, DataFrame):\n",
    "        raise TypeError(\"Entrada 'df' debe ser un Spark DataFrame.\")\n",
    "    if not isinstance(constant_value, (int, float)):\n",
    "        raise TypeError(\"Entrada'constant_value' debe ser un tipo numeric (int or float).\")\n",
    "\n",
    "    # Define the Spark numeric types this function will target\n",
    "    numeric_spark_types = (IntegerType, LongType, FloatType, DoubleType, DecimalType)\n",
    "\n",
    "    # Get all column names from the DataFrame's SCHEMA that are actually numeric types\n",
    "    df_actual_numeric_cols_from_schema = [f.name for f in df.schema.fields if isinstance(f.dataType, numeric_spark_types)]\n",
    "\n",
    "    # Your predefined lists for AEMET data\n",
    "    all_aemet_cols_conceptual = ['prob_precipitacion_00_24','cota_nieve_prov_00_24','estado_cielo_00_24_descripcion','estado_cielo_00_24_code','viento_direccion_00_24','viento_velocidad_00_24','racha_max_00_24','temperatura_maxima','temperatura_minima','sens_termica_maxima','sens_termica_minima','humedad_relativa_maxima','humedad_relativa_minima','uv_max']\n",
    "    string_aemet_cols_conceptual = ['estado_cielo_00_24_descripcion', 'viento_direccion_00_24']\n",
    "\n",
    "    # Determine the conceptual numeric columns based on your AEMET lists\n",
    "    conceptual_numeric_aemet_cols = list(set(all_aemet_cols_conceptual) - set(string_aemet_cols_conceptual))\n",
    "\n",
    "    # The final set of numeric columns to consider for imputation are those that are:\n",
    "    # 1. Actually numeric in the DataFrame's schema.\n",
    "    # 2. Present in your conceptual list of AEMET numeric columns.\n",
    "    # This ensures robustness.\n",
    "    all_numeric_cols_to_target = list(set(df_actual_numeric_cols_from_schema) & set(conceptual_numeric_aemet_cols))\n",
    "\n",
    "\n",
    "    if columns_to_impute:\n",
    "        # If specific columns are requested, filter them against the actual numeric target list\n",
    "        actual_columns_to_impute = [c for c in columns_to_impute if c in all_numeric_cols_to_target]\n",
    "        if len(actual_columns_to_impute) != len(columns_to_impute):\n",
    "            missing_or_non_target = set(columns_to_impute) - set(actual_columns_to_impute)\n",
    "            print(f\"Warning: Algunas columnas específicas ({missing_or_non_target}) no son target o no existen en el schema del DataFrame schema. Estas serán ignoradas.\")\n",
    "        numeric_cols_for_imputation = actual_columns_to_impute\n",
    "    else:\n",
    "        # If no specific columns, use all identified numeric target columns\n",
    "        numeric_cols_for_imputation = all_numeric_cols_to_target\n",
    "\n",
    "    if not numeric_cols_for_imputation:\n",
    "        print(\"No se encontraron ni seleccionaron columnas numéricas para la imputación según los criterios. No se realizaron cambios.\")\n",
    "        return df\n",
    "\n",
    "    print(f\"Imputando NULLs en columans numéricas con valor constante: '{constant_value}'...\")\n",
    "    print(f\"Columns affectadas: {', '.join(numeric_cols_for_imputation)}\")\n",
    "\n",
    "    columns_to_select = []\n",
    "    for column_name in df.columns:\n",
    "        if column_name in numeric_cols_for_imputation:\n",
    "            # coalesce replaces NULLs. For numerical types, NULL is the only \"empty\" value.\n",
    "            columns_to_select.append(\n",
    "                coalesce(col(column_name), lit(constant_value)).alias(column_name)\n",
    "            )\n",
    "        else:\n",
    "            columns_to_select.append(col(column_name))\n",
    "\n",
    "    return df.select(columns_to_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00452906",
   "metadata": {},
   "source": [
    "FUNCION PARA RELLENAR STRINGS NULLS Y BLANCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bac54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear una función para imputar nulos en las columnas de tipo StringType Spark DataFrame\n",
    "def imputeStringColumns(df: \"SPARK_DataFrame\", replacement_value: str = \"Desconocido\"):\n",
    "    \"\"\"\n",
    "    Imputa valores nulos en columnas de tipo StringType con un valor por defecto.\n",
    "    \"\"\"\n",
    "    string_cols=['estado_cielo_00_24_descripcion', 'viento_direccion_00_24', 'cota_nieve_prov_00_24', 'estado_cielo_00_24_code', 'racha_max_00_24']\n",
    "    #string_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType)]\n",
    "    #menos columnas específicas que no queremos imputar\n",
    "    #string_cols = [col for col in string_cols if col not in ['id', 'version']]  # Exclude 'id' and 'version' columns if they are StringType\n",
    "    # Exclude columns that are not StringType or that we don't want to impute   \n",
    "    #string_cols = [col for col in string_cols if col not in ['municipio_codigo_aemet', 'nombre_municipio_ine', 'fecha_descarga_utc', 'prediccion_fecha']] \n",
    "    \n",
    "    if not string_cols:\n",
    "        print(\"No se encontraron columns StringType para imputation.\")\n",
    "        return df\n",
    "\n",
    "    # Create a list of all columns, applying the imputation logic for StringType columns\n",
    "    columns_to_select = []\n",
    "    for column_name in df.columns:\n",
    "        if column_name in string_cols:\n",
    "            columns_to_select.append(\n",
    "                # Check if NULL OR if it's an empty string\n",
    "                when(col(column_name).isNull() | (col(column_name) == \"\"), lit(replacement_value))\n",
    "                .otherwise(col(column_name))\n",
    "                .alias(column_name)\n",
    "            )\n",
    "        else:\n",
    "            columns_to_select.append(col(column_name))\n",
    "            \n",
    "    print(f\"Imputando nulls y strings vacios es columnas con '{replacement_value}'...\")\n",
    "    print(f\"Columnas afectadas: {', '.join(string_cols)}\")\n",
    "\n",
    "    return df.select(columns_to_select)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a0874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- First 20 rows of df_daily_summary ---\n",
      "+----------------------+--------------------+--------------------------+-------------------+------------------------+---------------------+------------------------------+-----------------------+----------------------+----------------------+---------------+------------------+------------------+-------------------+-------------------+-----------------------+-----------------------+------+\n",
      "|municipio_codigo_aemet|nombre_municipio_ine|fecha_descarga_utc        |prediccion_fecha   |prob_precipitacion_00_24|cota_nieve_prov_00_24|estado_cielo_00_24_descripcion|estado_cielo_00_24_code|viento_direccion_00_24|viento_velocidad_00_24|racha_max_00_24|temperatura_maxima|temperatura_minima|sens_termica_maxima|sens_termica_minima|humedad_relativa_maxima|humedad_relativa_minima|uv_max|\n",
      "+----------------------+--------------------+--------------------------+-------------------+------------------------+---------------------+------------------------------+-----------------------+----------------------+----------------------+---------------+------------------+------------------+-------------------+-------------------+-----------------------+-----------------------+------+\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-25T00:00:00|0                       |NULL                 |                              |                       |                      |0                     |NULL           |31                |22                |31                 |22                 |75                     |55                     |9     |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-26T00:00:00|0                       |NULL                 |Despejado                     |11                     |E                     |15                    |NULL           |29                |23                |31                 |23                 |80                     |45                     |9     |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-27T00:00:00|0                       |NULL                 |Despejado                     |11                     |S                     |15                    |NULL           |31                |22                |31                 |22                 |70                     |55                     |9     |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-28T00:00:00|0                       |NULL                 |Despejado                     |11                     |SE                    |10                    |NULL           |31                |22                |31                 |22                 |75                     |55                     |10    |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-29T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |32                |23                |32                 |23                 |70                     |55                     |10    |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-06-30T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |32                |24                |32                 |24                 |70                     |55                     |NULL  |\n",
      "|12117                 |Torreblanca         |2025-06-25T17:14:50.215307|2025-07-01T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |34                |24                |34                 |24                 |70                     |50                     |NULL  |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-25T00:00:00|0                       |NULL                 |                              |                       |                      |0                     |NULL           |24                |13                |24                 |13                 |90                     |45                     |9     |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-26T00:00:00|0                       |NULL                 |Despejado                     |11                     |C                     |0                     |NULL           |29                |16                |29                 |16                 |75                     |30                     |9     |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-27T00:00:00|0                       |NULL                 |Despejado                     |11                     |C                     |0                     |NULL           |34                |20                |34                 |20                 |55                     |20                     |10    |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-28T00:00:00|0                       |NULL                 |Poco nuboso                   |12                     |C                     |0                     |NULL           |35                |23                |35                 |23                 |45                     |20                     |11    |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-29T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |37                |23                |37                 |23                 |40                     |15                     |11    |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-06-30T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |37                |23                |37                 |23                 |35                     |15                     |NULL  |\n",
      "|10134                 |Navezuelas          |2025-06-25T17:14:51.479434|2025-07-01T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |36                |23                |36                 |23                 |35                     |15                     |NULL  |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-25T00:00:00|0                       |NULL                 |                              |                       |                      |0                     |NULL           |31                |23                |31                 |23                 |60                     |30                     |9     |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-26T00:00:00|0                       |NULL                 |Despejado                     |11                     |S                     |15                    |NULL           |29                |24                |30                 |24                 |70                     |40                     |9     |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-27T00:00:00|0                       |NULL                 |Despejado                     |11                     |SE                    |15                    |NULL           |29                |23                |29                 |23                 |80                     |50                     |9     |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-28T00:00:00|0                       |NULL                 |Despejado                     |11                     |S                     |15                    |NULL           |29                |23                |29                 |23                 |90                     |55                     |10    |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-29T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |31                |24                |31                 |24                 |75                     |45                     |10    |\n",
      "|08019                 |Barcelona           |2025-06-25T17:14:52.681853|2025-06-30T00:00:00|NULL                    |NULL                 |NULL                          |NULL                   |NULL                  |NULL                  |NULL           |32                |25                |32                 |25                 |60                     |40                     |NULL  |\n",
      "+----------------------+--------------------+--------------------------+-------------------+------------------------+---------------------+------------------------------+-----------------------+----------------------+----------------------+---------------+------------------+------------------+-------------------+-------------------+-----------------------+-----------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Leemos los datos de la tabla iceberg\n",
    "df_raw_aemet = spark.read.format(\"iceberg\").load(\"spark_catalog.local_db.aemet\")\n",
    "\n",
    "# Define the schema for the nested JSON string in 'raw_aemet_data_json_str'\n",
    "aemet_data_schema = ArrayType(StructType([\n",
    "    StructField(\"origen\", StructType([\n",
    "        StructField(\"productor\", StringType(), True),\n",
    "        StructField(\"web\", StringType(), True),\n",
    "        StructField(\"enlace\", StringType(), True),\n",
    "        StructField(\"language\", StringType(), True),\n",
    "        StructField(\"copyright\", StringType(), True),\n",
    "        StructField(\"notaLegal\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"elaborado\", StringType(), True),\n",
    "    StructField(\"nombre\", StringType(), True),\n",
    "    StructField(\"provincia\", StringType(), True),\n",
    "    StructField(\"prediccion\", StructType([\n",
    "        StructField(\"dia\", ArrayType(StructType([\n",
    "            StructField(\"probPrecipitacion\", ArrayType(StructType([\n",
    "                StructField(\"value\", IntegerType(), True),\n",
    "                StructField(\"periodo\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"cotaNieveProv\", ArrayType(StructType([\n",
    "                StructField(\"value\", IntegerType(), True),\n",
    "                StructField(\"periodo\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"estadoCielo\", ArrayType(StructType([\n",
    "                StructField(\"value\", StringType(), True),\n",
    "                StructField(\"periodo\", StringType(), True),\n",
    "                StructField(\"descripcion\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"viento\", ArrayType(StructType([\n",
    "                StructField(\"direccion\", StringType(), True),\n",
    "                StructField(\"velocidad\", IntegerType(), True),\n",
    "                StructField(\"periodo\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"rachaMax\", ArrayType(StructType([\n",
    "                StructField(\"value\", IntegerType(), True),\n",
    "                StructField(\"periodo\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"temperatura\", StructType([\n",
    "                StructField(\"maxima\", IntegerType(), True),\n",
    "                StructField(\"minima\", IntegerType(), True),\n",
    "                StructField(\"dato\", ArrayType(StructType([\n",
    "                    StructField(\"value\", IntegerType(), True),\n",
    "                    StructField(\"hora\", IntegerType(), True)\n",
    "                ])), True)\n",
    "            ]), True),\n",
    "            StructField(\"sensTermica\", StructType([\n",
    "                StructField(\"maxima\", IntegerType(), True),\n",
    "                StructField(\"minima\", IntegerType(), True),\n",
    "                StructField(\"dato\", ArrayType(StructType([\n",
    "                    StructField(\"value\", IntegerType(), True),\n",
    "                    StructField(\"hora\", IntegerType(), True)\n",
    "                ])), True)\n",
    "            ]), True),\n",
    "            StructField(\"humedadRelativa\", StructType([\n",
    "                StructField(\"maxima\", IntegerType(), True),\n",
    "                StructField(\"minima\", IntegerType(), True),\n",
    "                StructField(\"dato\", ArrayType(StructType([\n",
    "                    StructField(\"value\", IntegerType(), True),\n",
    "                    StructField(\"hora\", IntegerType(), True)\n",
    "                ])), True)\n",
    "            ]), True),\n",
    "            StructField(\"uvMax\", IntegerType(), True),\n",
    "            StructField(\"fecha\", StringType(), True)\n",
    "        ])), True)\n",
    "    ]), True),\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"version\", DoubleType(), True)\n",
    "]))\n",
    "\n",
    "# Apply the from_json function to parse the raw_aemet_data_json_str column\n",
    "df_parsed = df_raw_aemet.withColumn(\n",
    "    \"parsed_aemet_data\",\n",
    "    F.from_json(F.col(\"raw_aemet_data_json_str\"), aemet_data_schema)\n",
    ")\n",
    "\n",
    "# Explode the 'dia' array to get one row per day for each municipality\n",
    "df_exploded_days = df_parsed.withColumn(\n",
    "    \"day_data\",\n",
    "    F.explode_outer(F.col(\"parsed_aemet_data\").getItem(0).getField(\"prediccion\").getField(\"dia\"))\n",
    ")\n",
    "\n",
    "# Function to filter an array of structs for the \"00-24\" period and get its value\n",
    "def get_period_value(col_name, value_field=\"value\"):\n",
    "    return F.expr(f\"\"\"\n",
    "        FILTER({col_name}, element -> element.periodo = '00-24')[0].{value_field}\n",
    "    \"\"\")\n",
    "\n",
    "# Select and extract the desired data, focusing on the '00-24' period for relevant arrays\n",
    "df_daily_summary = df_exploded_days.select(\n",
    "    F.col(\"municipio_codigo_aemet\"),\n",
    "    F.col(\"nombre_municipio_ine\"),\n",
    "    F.col(\"fecha_descarga_utc\"),\n",
    "    F.col(\"day_data.fecha\").alias(\"prediccion_fecha\"),\n",
    "\n",
    "    # Probabilidad de precipitación 00-24\n",
    "    get_period_value(\"day_data.probPrecipitacion\", \"value\").alias(\"prob_precipitacion_00_24\"),\n",
    "\n",
    "    # Cota de nieve provincial 00-24\n",
    "    get_period_value(\"day_data.cotaNieveProv\", \"value\").alias(\"cota_nieve_prov_00_24\"),\n",
    "\n",
    "    # Estado del cielo 00-24\n",
    "    get_period_value(\"day_data.estadoCielo\", \"descripcion\").alias(\"estado_cielo_00_24_descripcion\"),\n",
    "    get_period_value(\"day_data.estadoCielo\", \"value\").alias(\"estado_cielo_00_24_code\"),\n",
    "\n",
    "    # Viento 00-24\n",
    "    get_period_value(\"day_data.viento\", \"direccion\").alias(\"viento_direccion_00_24\"),\n",
    "    get_period_value(\"day_data.viento\", \"velocidad\").alias(\"viento_velocidad_00_24\"),\n",
    "\n",
    "    # Racha máxima 00-24\n",
    "    get_period_value(\"day_data.rachaMax\", \"value\").alias(\"racha_max_00_24\"),\n",
    "\n",
    "    # Temperatura\n",
    "    F.col(\"day_data.temperatura.maxima\").alias(\"temperatura_maxima\"),\n",
    "    F.col(\"day_data.temperatura.minima\").alias(\"temperatura_minima\"),\n",
    "\n",
    "    # Sensación térmica\n",
    "    F.col(\"day_data.sensTermica.maxima\").alias(\"sens_termica_maxima\"),\n",
    "    F.col(\"day_data.sensTermica.minima\").alias(\"sens_termica_minima\"),\n",
    "\n",
    "    # Humedad Relativa\n",
    "    F.col(\"day_data.humedadRelativa.maxima\").alias(\"humedad_relativa_maxima\"),\n",
    "    F.col(\"day_data.humedadRelativa.minima\").alias(\"humedad_relativa_minima\"),\n",
    "\n",
    "    # UV Max\n",
    "    F.col(\"day_data.uvMax\").alias(\"uv_max\")\n",
    ")\n",
    "\n",
    "# Show the schema and some results\n",
    "#print(\"\\n--- Schema of df_daily_summary ---\")\n",
    "#df_daily_summary.printSchema()\n",
    "\n",
    "print(\"\\n--- First 20 rows of df_daily_summary ---\")\n",
    "df_daily_summary.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376da009",
   "metadata": {},
   "source": [
    "IMPUTACION DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c91be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputando NULLs en columans numéricas con valor constante: '-9999'...\n",
      "Columns affectadas: cota_nieve_prov_00_24, prob_precipitacion_00_24, viento_velocidad_00_24, sens_termica_minima, humedad_relativa_maxima, humedad_relativa_minima, racha_max_00_24, temperatura_minima, temperatura_maxima, sens_termica_maxima, uv_max\n",
      "Imputando nulls y strings vacios es columnas con 'Desconocido'...\n",
      "Columnas afectadas: estado_cielo_00_24_descripcion, viento_direccion_00_24, cota_nieve_prov_00_24, estado_cielo_00_24_code, racha_max_00_24\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Impute missing values in numeric and string columns\n",
    "# Note: This is a simplified example. In practice, you might want to handle different types of missing values differently.\n",
    "# Impute numeric columns with a constant value of -9999 \n",
    "df_imputed = (df_daily_summary\n",
    "              .transform(imputeNumericColumns, constant_value=-9999)\n",
    "              .transform(imputeStringColumns, replacement_value=\"Desconocido\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e3972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TravelMind-D0cwe-Yj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
