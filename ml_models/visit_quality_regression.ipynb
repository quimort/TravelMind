{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cc719e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from builtins import min as python_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d08834",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = utils.create_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b031966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading hotel occupancy data...\n",
      "    Hotel records: 265\n",
      "‚úÖ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load weather data\n",
    "#print(\"  Loading weather data...\")\n",
    "#df_weather = utils.read_iceberg_table( spark, \"trusted\", \"aemetTrustedDiario\")\n",
    "#\n",
    "#weather_count = df_weather.count()\n",
    "#print(f\"    Weather records: {weather_count}\")\n",
    "\n",
    "# Load hotel occupancy data\n",
    "print(\"  Loading hotel occupancy data...\")\n",
    "df_hotels = utils.read_iceberg_table(spark=spark, db_name=\"exploitation\", table_name=\"f_ocupacion_barcelona\")\n",
    "hotel_count = df_hotels.count()\n",
    "print(f\"    Hotel records: {hotel_count}\")\n",
    "\n",
    "print(\"‚úÖ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d7e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hotel_features(df_hotels):\n",
    "        \"\"\"Create hotel-based features.\"\"\"\n",
    "        print(\"  Creating hotel features...\")\n",
    "        \n",
    "        df_hotel_features = df_hotels.groupBy(\n",
    "            col('a√±o'),\n",
    "            col('mes')\n",
    "        ).agg(\n",
    "            sum('viajeros').alias('hotel_viajeros'),\n",
    "            sum('pernoctaciones').alias('hotel_pernoctaciones'),\n",
    "            avg('estanciaMedia').alias('hotel_estancia_media'),\n",
    "            avg('gradoOcupaPlazas').alias('avg_ocupacion')\n",
    "        ).withColumn(\n",
    "            # Hotel availability score\n",
    "            'hotel_availability_score',\n",
    "            100 - col('avg_ocupacion')\n",
    "        )\n",
    "        \n",
    "        return df_hotel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df32726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating hotel features...\n"
     ]
    }
   ],
   "source": [
    "df_hotel_feat = create_hotel_features(df_hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318d2df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel_feat = (\n",
    "    df_hotel_feat\n",
    "    .withColumn(\n",
    "            # Seasonal score\n",
    "            'seasonal_score',\n",
    "            when((col('mes').isin([6, 7, 8])), 90)  # Summer\n",
    "            .when((col('mes').isin([4, 5, 9, 10])), 85)  # Spring/Fall\n",
    "            .when((col('mes').isin([11, 12, 1, 2, 3])), 60)  # Winter\n",
    "            .otherwise(70)\n",
    "        )\n",
    "    .withColumn(\n",
    "            'visit_quality_score',\n",
    "            (coalesce(col('hotel_availability_score'), lit(75)) * 0.1)\n",
    "        )\n",
    ")\n",
    "\n",
    "df_final = (\n",
    "    df_hotel_feat\n",
    "    .na.drop()\n",
    "\n",
    ")\n",
    "final_count = df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d87b5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training data: 133 rows\n",
      "  Test data: 25 rows\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"  Training data: {train_data.count()} rows\")\n",
    "print(f\"  Test data: {test_data.count()} rows\")\n",
    "\n",
    "optional_features = [\n",
    "    'total_viajeros', 'total_pernoctaciones', 'avg_estancia_media',\n",
    "    'hotel_viajeros', 'hotel_pernoctaciones', 'avg_ocupacion'\n",
    "]\n",
    "\n",
    "# Check which optional features are available\n",
    "available_features = []\n",
    "for feat in optional_features:\n",
    "    if feat in df_final.columns:\n",
    "        available_features.append(feat)\n",
    "\n",
    "feature_names = available_features\n",
    "def create_models(feature_names) -> dict:\n",
    "\n",
    "    \"\"\"Create ML models.\"\"\"\n",
    "    print(\"\\nü§ñ Creating ML models...\")\n",
    "    \n",
    "    # Prepare features for ML\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=feature_names,\n",
    "        outputCol='features'\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler(\n",
    "        inputCol='features',\n",
    "        outputCol='scaled_features'\n",
    "    )\n",
    "    \n",
    "    # Create models\n",
    "    lr = LinearRegression(\n",
    "        featuresCol='scaled_features',\n",
    "        labelCol='visit_quality_score',\n",
    "        predictionCol='prediction'\n",
    "    )\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        featuresCol='scaled_features',\n",
    "        labelCol='visit_quality_score',\n",
    "        predictionCol='prediction',\n",
    "        numTrees=100,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    gbt = GBTRegressor(\n",
    "        featuresCol='scaled_features',\n",
    "        labelCol='visit_quality_score',\n",
    "        predictionCol='prediction',\n",
    "        maxIter=100,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    models = {\n",
    "        'LinearRegression': Pipeline(stages=[assembler, scaler, lr]),\n",
    "        'RandomForest': Pipeline(stages=[assembler, scaler, rf]),\n",
    "        'GradientBoosting': Pipeline(stages=[assembler, scaler, gbt])\n",
    "    }\n",
    "    \n",
    "    print(f\"  Created {len(models)} models: {list(models.keys())}\")\n",
    "    print(\"‚úÖ Models created\")\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c6629e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(models, train_data, test_data):\n",
    "    \"\"\"Train and evaluate all models.\"\"\"\n",
    "    print(\"\\nüèãÔ∏è Training and evaluating models...\")\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol='visit_quality_score',\n",
    "        predictionCol='prediction'\n",
    "    )\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n  Training {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model_fitted = model.fit(train_data)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model_fitted.transform(test_data)\n",
    "            \n",
    "            # Evaluate\n",
    "            rmse = evaluator.evaluate(predictions, {evaluator.metricName: 'rmse'})\n",
    "            mae = evaluator.evaluate(predictions, {evaluator.metricName: 'mae'})\n",
    "            r2 = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\n",
    "            \n",
    "            results[name] = {\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'R2': r2,\n",
    "                'model': model_fitted,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "            \n",
    "            print(f\"    RMSE: {rmse:.3f}\")\n",
    "            print(f\"    MAE: {mae:.3f}\")\n",
    "            print(f\"    R¬≤: {r2:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Error training {name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    \n",
    "    if results:\n",
    "        best_model_name = python_min(results.keys(), key=lambda x: results[x]['RMSE'])\n",
    "        best_model = results[best_model_name]['model']\n",
    "        \n",
    "        print(f\"\\nüèÜ Best model: {best_model_name}\")\n",
    "        print(f\"   RMSE: {results[best_model_name]['RMSE']:.3f}\")\n",
    "        print(f\"   R¬≤: {results[best_model_name]['R2']:.3f}\")\n",
    "    \n",
    "    print(\"‚úÖ Training and evaluation completed\")\n",
    "    \n",
    "    return results, best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66b2c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results, best_model_name, best_model, feature_names):\n",
    "    \"\"\"Analyze and visualize results.\"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    print(\"\\nüìà Analyzing results...\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"‚ùå No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Feature importance analysis (for tree-based models)\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "        print(\"\\nüîç Feature Importance Analysis:\")\n",
    "        try:\n",
    "            feature_importance = best_model.stages[-1].featureImportances.toArray()\n",
    "            \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': feature_importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 10 Most Important Features:\")\n",
    "            print(importance_df.head(10).to_string(index=False))\n",
    "            \n",
    "            # Create output directory if it doesn't exist\n",
    "            os.makedirs('ml_models', exist_ok=True)\n",
    "            \n",
    "            # Save feature importance\n",
    "            importance_df.to_csv('ml_models/feature_importance.csv', index=False)\n",
    "            print(\"\\nüíæ Feature importance saved to feature_importance.csv\")\n",
    "            \n",
    "            # Return for further analysis in notebook\n",
    "            feature_importance_result = importance_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error analyzing feature importance: {e}\")\n",
    "            feature_importance_result = None\n",
    "    else:\n",
    "        feature_importance_result = None\n",
    "    \n",
    "    # Prediction analysis\n",
    "    prediction_stats = None\n",
    "    pred_df = None\n",
    "    \n",
    "    try:\n",
    "        best_predictions = results[best_model_name]['predictions']\n",
    "        \n",
    "        # Convert to Pandas for analysis\n",
    "        pred_df = best_predictions.select(\n",
    "             'visit_quality_score', 'prediction'\n",
    "        ).toPandas()\n",
    "        \n",
    "        print(f\"\\nüìä Prediction Statistics:\")\n",
    "        print(f\"   Mean Actual Score: {pred_df['visit_quality_score'].mean():.2f}\")\n",
    "        print(f\"   Mean Predicted Score: {pred_df['prediction'].mean():.2f}\")\n",
    "        print(f\"   Std Actual Score: {pred_df['visit_quality_score'].std():.2f}\")\n",
    "        print(f\"   Std Predicted Score: {pred_df['prediction'].std():.2f}\")\n",
    "        \n",
    "        # Create prediction statistics dictionary\n",
    "        prediction_stats = {\n",
    "            'mean_actual': pred_df['visit_quality_score'].mean(),\n",
    "            'mean_predicted': pred_df['prediction'].mean(),\n",
    "            'std_actual': pred_df['visit_quality_score'].std(),\n",
    "            'std_predicted': pred_df['prediction'].std()\n",
    "        }\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs('ml_models', exist_ok=True)\n",
    "        \n",
    "        # Save predictions\n",
    "        pred_df.to_csv('ml_models/predictions.csv', index=False)\n",
    "        print(\"\\nüíæ Predictions saved to predictions.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing predictions: {e}\")\n",
    "    \n",
    "    print(\"‚úÖ Results analysis completed\")\n",
    "    \n",
    "    # Return analysis results for further use in notebook\n",
    "    return {\n",
    "        'feature_importance': feature_importance_result,\n",
    "        'prediction_stats': prediction_stats,\n",
    "        'predictions_df': pred_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d2536ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Creating ML models...\n",
      "  Created 3 models: ['LinearRegression', 'RandomForest', 'GradientBoosting']\n",
      "‚úÖ Models created\n",
      "\n",
      "üèãÔ∏è Training and evaluating models...\n",
      "\n",
      "  Training LinearRegression...\n",
      "    RMSE: 0.000\n",
      "    MAE: 0.000\n",
      "    R¬≤: 1.000\n",
      "\n",
      "  Training RandomForest...\n",
      "    RMSE: 0.400\n",
      "    MAE: 0.317\n",
      "    R¬≤: 0.939\n",
      "\n",
      "  Training GradientBoosting...\n",
      "    RMSE: 0.140\n",
      "    MAE: 0.100\n",
      "    R¬≤: 0.993\n",
      "\n",
      "üèÜ Best model: LinearRegression\n",
      "   RMSE: 0.000\n",
      "   R¬≤: 1.000\n",
      "‚úÖ Training and evaluation completed\n",
      "\n",
      "üìà Analyzing results...\n",
      "\n",
      "üìä Prediction Statistics:\n",
      "   Mean Actual Score: 4.34\n",
      "   Mean Predicted Score: 4.34\n",
      "   Std Actual Score: 1.65\n",
      "   Std Predicted Score: 1.65\n",
      "\n",
      "üíæ Predictions saved to predictions.csv\n",
      "‚úÖ Results analysis completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature_importance': None,\n",
       " 'prediction_stats': {'mean_actual': np.float64(4.34214),\n",
       "  'mean_predicted': np.float64(4.3421399999999855),\n",
       "  'std_actual': np.float64(1.652334236012799),\n",
       "  'std_predicted': np.float64(1.6523342360128401)},\n",
       " 'predictions_df':     visit_quality_score  prediction\n",
       " 0                3.9640      3.9640\n",
       " 1                1.7320      1.7320\n",
       " 2                2.5180      2.5180\n",
       " 3                4.9720      4.9720\n",
       " 4                1.6570      1.6570\n",
       " 5                5.5180      5.5180\n",
       " 6                2.7390      2.7390\n",
       " 7                5.2410      5.2410\n",
       " 8                2.5170      2.5170\n",
       " 9                4.0920      4.0920\n",
       " 10               5.1650      5.1650\n",
       " 11               5.4135      5.4135\n",
       " 12               4.0350      4.0350\n",
       " 13               1.5915      1.5915\n",
       " 14               4.5525      4.5525\n",
       " 15               3.6025      3.6025\n",
       " 16               2.7225      2.7225\n",
       " 17               6.6720      6.6720\n",
       " 18               3.4300      3.4300\n",
       " 19               6.3590      6.3590\n",
       " 20               7.2455      7.2455\n",
       " 21               5.9385      5.9385\n",
       " 22               6.0090      6.0090\n",
       " 23               5.0370      5.0370\n",
       " 24               5.8300      5.8300}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = create_models(feature_names)\n",
    "results, best_model_name, best_model = train_and_evaluate(models,train_data,test_data)\n",
    "analyze_results(results,best_model_name,best_model,feature_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TravelMind-69GU69Sq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
