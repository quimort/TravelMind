{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6da74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import utils as utils\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from builtins import min as python_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbf44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = utils.create_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb515de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading hotel occupancy data...\n",
      "    Hotel records: 265\n",
      "âœ… Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load weather data\n",
    "#print(\"  Loading weather data...\")\n",
    "#df_weather = utils.read_iceberg_table( spark, \"trusted\", \"aemetTrustedDiario\")\n",
    "#\n",
    "#weather_count = df_weather.count()\n",
    "#print(f\"    Weather records: {weather_count}\")\n",
    "\n",
    "# Load hotel occupancy data\n",
    "print(\"  Loading hotel occupancy data...\")\n",
    "df_hotels = utils.read_iceberg_table(spark=spark, db_name=\"exploitation\", table_name=\"f_ocupacion_barcelona\")\n",
    "hotel_count = df_hotels.count()\n",
    "print(f\"    Hotel records: {hotel_count}\")\n",
    "\n",
    "print(\"âœ… Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7e610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hotel_features(df_hotels):\n",
    "        \"\"\"Create hotel-based features.\"\"\"\n",
    "        print(\"  Creating hotel features...\")\n",
    "        \n",
    "        df_hotel_features = df_hotels.groupBy(\n",
    "            col('aÃ±o'),\n",
    "            col('mes')\n",
    "        ).agg(\n",
    "            sum('viajeros').alias('hotel_viajeros'),\n",
    "            sum('pernoctaciones').alias('hotel_pernoctaciones'),\n",
    "            avg('estanciaMedia').alias('hotel_estancia_media'),\n",
    "            avg('gradoOcupaPlazas').alias('avg_ocupacion')\n",
    "        ).withColumn(\n",
    "            # Hotel availability score\n",
    "            'hotel_availability_score',\n",
    "            100 - col('avg_ocupacion')\n",
    "        )\n",
    "        \n",
    "        return df_hotel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857f2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Creating hotel features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 18:20:45,701 INFO XGBoost-PySpark: _fit Running xgboost-3.0.4 on 1 workers with\n",
      "\tbooster params: {'objective': 'binary:logistic', 'device': 'cpu', 'max_depth': 5, 'scale_pos_weight': 0.9506172839506173, 'num_round': 50, 'eta': 0.1, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-08-26 18:20:52,976 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+-----------------------------------------+----------+\n",
      "|aÃ±o |mes|label|probability                              |prediction|\n",
      "+----+---+-----+-----------------------------------------+----------+\n",
      "|2012|3  |0    |[0.015503287315368652,0.9844967126846313]|1.0       |\n",
      "|2012|7  |0    |[0.9854826927185059,0.01451731938868761] |0.0       |\n",
      "|2012|9  |0    |[0.9854826927185059,0.01451731938868761] |0.0       |\n",
      "|2013|2  |1    |[0.015503287315368652,0.9844967126846313]|1.0       |\n",
      "|2013|8  |0    |[0.9854826927185059,0.01451731938868761] |0.0       |\n",
      "|2013|12 |1    |[0.015503287315368652,0.9844967126846313]|1.0       |\n",
      "|2014|6  |0    |[0.9854826927185059,0.01451731938868761] |0.0       |\n",
      "|2014|12 |1    |[0.015503287315368652,0.9844967126846313]|1.0       |\n",
      "|2015|10 |0    |[0.9854826927185059,0.01451731938868761] |0.0       |\n",
      "|2015|11 |1    |[0.015503287315368652,0.9844967126846313]|1.0       |\n",
      "+----+---+-----+-----------------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. Generar features a partir de df_hotels\n",
    "df_hotel_features = create_hotel_features(df_hotels)\n",
    "\n",
    "# ðŸš¨ AquÃ­ necesitas una etiqueta (label).\n",
    "# Ejemplo: 1 si es \"buen momento\", 0 si no. \n",
    "# Esto normalmente lo defines con criterios propios.\n",
    "# Supongamos que un buen momento es cuando hotel_availability_score > 40\n",
    "df_labeled = df_hotel_features.withColumn(\n",
    "    \"label\", (col(\"hotel_availability_score\") > 40).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 3. Seleccionar las features para el modelo\n",
    "feature_cols = [\n",
    "    \"hotel_viajeros\",\n",
    "    \"hotel_pernoctaciones\",\n",
    "    \"hotel_estancia_media\",\n",
    "    \"avg_ocupacion\",\n",
    "    \"hotel_availability_score\"\n",
    "]\n",
    "\n",
    "# VectorAssembler para convertir a vector de features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "# Contar positivos (label=1) y negativos (label=0)\n",
    "counts = df_labeled.groupBy(\"label\").count().collect()\n",
    "\n",
    "# Inicializamos variables\n",
    "num_positivos = 0\n",
    "num_negativos = 0\n",
    "\n",
    "for row in counts:\n",
    "    if row['label'] == 1:\n",
    "        num_positivos = row['count']\n",
    "    else:\n",
    "        num_negativos = row['count']\n",
    "\n",
    "# Ratio para scale_pos_weight\n",
    "ratio_negativos_sobre_positivos = num_negativos / num_positivos\n",
    "# 4. Definir modelo XGBoost\n",
    "xgb = SparkXGBClassifier(\n",
    "    features_col=\"features\",       # <- snake_case\n",
    "    label_col=\"label\",\n",
    "    prediction_col=\"prediction\",\n",
    "    probability_col=\"probability\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.1,\n",
    "    scale_pos_weight=ratio_negativos_sobre_positivos\n",
    ")\n",
    "\n",
    "# 5. Construir pipeline\n",
    "pipeline = Pipeline(stages=[assembler, xgb])\n",
    "\n",
    "# 6. Entrenar modelo\n",
    "train, test = df_labeled.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# 7. Evaluar modelo\n",
    "predictions = model.transform(test)\n",
    "predictions.select(\"aÃ±o\", \"mes\", \"label\", \"probability\", \"prediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c70287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+----------------------------------------+\n",
      "|aÃ±o |mes|prediction|probability                             |\n",
      "+----+---+----------+----------------------------------------+\n",
      "|2025|9  |0.0       |[0.9854826927185059,0.01451731938868761]|\n",
      "+----+---+----------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Supongamos que queremos predecir para Barcelona, 20/09/2025\n",
    "ciudad = \"Barcelona\"\n",
    "fecha = \"2025-09-20\"\n",
    "year, month, day = map(int, fecha.split(\"-\"))\n",
    "\n",
    "# Generar features para esa fecha\n",
    "# En tu caso, solo agregados histÃ³ricos por mes y aÃ±o\n",
    "# AquÃ­ podemos usar medias histÃ³ricas del mes de septiembre\n",
    "df_month_avg = df_hotel_features.filter(col(\"mes\") == month).agg(\n",
    "    avg(\"hotel_viajeros\").alias(\"hotel_viajeros\"),\n",
    "    avg(\"hotel_pernoctaciones\").alias(\"hotel_pernoctaciones\"),\n",
    "    avg(\"hotel_estancia_media\").alias(\"hotel_estancia_media\"),\n",
    "    avg(\"avg_ocupacion\").alias(\"avg_ocupacion\"),\n",
    "    avg(\"hotel_availability_score\").alias(\"hotel_availability_score\")\n",
    ").collect()[0]\n",
    "\n",
    "# Crear fila para predicciÃ³n\n",
    "future_row = Row(\n",
    "    aÃ±o=year,\n",
    "    mes=month,\n",
    "    hotel_viajeros=df_month_avg[\"hotel_viajeros\"],\n",
    "    hotel_pernoctaciones=df_month_avg[\"hotel_pernoctaciones\"],\n",
    "    hotel_estancia_media=df_month_avg[\"hotel_estancia_media\"],\n",
    "    avg_ocupacion=df_month_avg[\"avg_ocupacion\"],\n",
    "    hotel_availability_score=df_month_avg[\"hotel_availability_score\"]\n",
    ")\n",
    "\n",
    "# Convertir a DataFrame Spark\n",
    "future_df = spark.createDataFrame([future_row])\n",
    "\n",
    "# Aplicar pipeline entrenado\n",
    "prediction = model.transform(future_df)\n",
    "\n",
    "# Mostrar resultado\n",
    "prediction.select(\n",
    "    \"aÃ±o\", \"mes\", \"prediction\", \"probability\"\n",
    ").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TravelMind-69GU69Sq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
